{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3781ad86-46dc-49e0-8f2f-15058d2f90e0",
   "metadata": {},
   "source": [
    "# Q1. What is hierarchical clustering, and how is it different from other clustering techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62cb70-cc62-4567-9c14-653781c321b3",
   "metadata": {},
   "source": [
    " Hierarchical clustering is a method for clustering data points into a hierarchy of clusters. Unlike other clustering techniques, hierarchical clustering creates a tree-like structure of clusters, which can be visualized as a dendrogram. It is different from methods like K-means because it doesn't require specifying the number of clusters in advance and produces a hierarchy of clusters rather than a single partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d645e15-94ca-42c6-a19d-6fce98803562",
   "metadata": {},
   "source": [
    "# Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df4bae-30b6-4d51-a1d1-2ae450a37fed",
   "metadata": {},
   "source": [
    "a. Agglomerative Hierarchical Clustering: This method starts with each data point as a separate cluster and iteratively merges the closest clusters until all data points belong to a single cluster. It builds the hierarchy bottom-up.\n",
    "\n",
    "b. Divisive Hierarchical Clustering: This method starts with all data points in a single cluster and recursively divides clusters into smaller clusters until each data point is in its own cluster. It builds the hierarchy top-down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc62b0-ddfa-4eda-8730-84293f1bdf6a",
   "metadata": {},
   "source": [
    "# Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the common distance metrics used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7755ed-2905-43e7-87cf-8d2417dd135d",
   "metadata": {},
   "source": [
    " The distance between two clusters in hierarchical clustering is determined using a distance metric that measures the dissimilarity or similarity between the data points in those clusters. Common distance metrics used in hierarchical clustering include:\n",
    "\n",
    "Euclidean distance\n",
    "\n",
    "Manhattan distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043c7d4-605d-45d7-9936-62af195dc740",
   "metadata": {},
   "source": [
    "# Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some common methods used for this purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be7713-421d-4ac7-a328-06a2c1e1ee45",
   "metadata": {},
   "source": [
    " Determining the optimal number of clusters in hierarchical clustering can be done using methods such as:\n",
    "\n",
    "Dendrogram analysis: Visual inspection of the dendrogram to identify a point where clusters start to merge less distinctly, indicating the number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9880631-8688-4247-8c82-73999404ed71",
   "metadata": {},
   "source": [
    "# Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87fb40-31c0-4c79-b5d2-a1ae9903024d",
   "metadata": {},
   "source": [
    ". Dendrograms in hierarchical clustering are tree-like structures that represent the hierarchy of clusters. They are useful in analyzing the results by visually displaying the clustering process. By examining the dendrogram, you can identify the level at which you want to cut the tree to obtain a specific number of clusters. Dendrograms also help in understanding the relationships between clusters at different levels of granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3161cd-6e0e-4fef-b2ae-529f7169fb8f",
   "metadata": {},
   "source": [
    "# Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the distance metrics different for each type of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca697f-269f-4002-8f0b-7cac1a3b6fe4",
   "metadata": {},
   "source": [
    "For numerical data, commonly used distance metrics include Euclidean distance, Manhattan distance, and correlation-based distances.\n",
    "For categorical data, you can use distance metrics tailored to categorical variables, such as the Jaccard distance, Hamming distance, or Gower's distance, which handle the discrete nature of categorical attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3f9244-52d5-4355-9f5a-d9129858f535",
   "metadata": {},
   "source": [
    "# Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6b67e-7429-4cb5-ba0f-08c7bbb83bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
